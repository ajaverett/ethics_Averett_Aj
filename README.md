# Ethics Manifesto 

Codes of ethics cannot work if they are meant to act as mere rules on companies. Data Science and its many branches, with its inherent power to shape decisions and policies, needs a code of ethics that is both practical and adaptable. It needs to promote only three things: pro-social outcomes, company transparency, and customer privacy.

### Prosocial outcomes

We can quantify if any-given interactive application is prosocial by the amount of time someone spends per day within it. This correctly implies that the optimal amount of time someone spends on an interactive application is zero. 

Assuming we require companies to track average customer usage, if we were to tax or give negative incentives to companies for the amount of time the median customer spends on their application, this could incentivize several things:

-	Designing for Quality over Quantity: Companies would be encouraged to create applications that prioritize quality of experience over addictive features. This shift in focus could lead to more meaningful, enriching interactions with technology, rather than prolonged, mindless usage.

- Promoting Digital Well-being: This approach could lead to the development of features that promote digital well-being. Applications might include tools for managing screen time, setting usage goals, or even reminders to take breaks, all designed to enhance the user's overall well-being.

- Shifting Business Models: Companies might explore new business models that don't rely on maximized screen time for profitability. This could lead to more innovative and sustainable approaches to monetization, which don't exploit user attention.



### Company transparency

The goal that many saw with the future of AI is that of convenience. Technology ideally would allow itself to become the background tasks that humans take center stage in. Misguided attempts to promote safety propose that the best idea for privacy is to not collect nor store user information or data at all. This idea destroys user convenience and ad revenue that pays for costs at every company. If we are able to collect data in order to allow automations that increase user convenience (by decreasing raw interaction time), this is good. 

Despite this goal, transparency in data science is still crucial for ethical operations. Companies should be mandated to disclose how and what data is collected, processed, and stored- not only in broad terms but in a way that is easily understandable to the average user. This transparency extends beyond privacy policies to include the algorithms and decision-making processes. Additionally, if there are any AI tools that customers receive any interaction with, there must be an accessible place to read about all the features that contribute to this.

Instead of penalizing the existence of user data storage, we can incentivize responsible data usage by laws that take into account the amount of data and the ratio and effect size of the data that decreases use time using random A/B testing.

### Customer Privacy

One of the most important features of a secure company is how they handle or mishandle user data. User data is one of many company practices that can be easily handled through the stick- not the carrot. Companies uphold the responsibility to maintain user data securely- which scales nicely. As the amount of user data increases, a company basically has to increase the security measures for fear of hackers or leaks. As the amount of user data increases, the consequences increase for the amount of user data leaked.
